{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Simple Model with PyTorch\n",
    "\n",
    "This is \"boilerplate\" code to train a simple model with PyTorch.\n",
    " \n",
    "You can adapt this code for a variety of tasks.\n",
    "\n",
    "There are four major parts:\n",
    "\n",
    "  1.  Read training data\n",
    "  2.  Construct a model\n",
    "  3.  Train the model\n",
    "  4.  Output the model\n",
    "\n",
    "These steps are described in more detail below.\n",
    "\n",
    "As a concrete example, this code reads training data from the file named \"example.csv\", constructs a simple model, and trains that model to fit the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Training Data\n",
    "\n",
    "Training data consists of many training examples.  Each training example specifies inputs to the model and the desired output.\n",
    "\n",
    "The training data is stored in a CSV file.  CSV stands for \"comma separated values\".  As the name suggests, a CSV file consists of a sequence of lines, where each line contains several values.  Here is an example:\n",
    "\n",
    "    0.682,1.704,9.740\n",
    "    0.150,1.252,4.331\n",
    "    1.741,0.159,12.838\n",
    "    1.575,1.586,16.1647\n",
    "\n",
    "Each row in the CSV file represents one training example.  The last number is the desired model output, and the preceding numbers are the model inputs. So, for example, the first row of the CSV above means:\n",
    "\n",
    ">   \"When the model gets the numbers 0.682 and 1.704 as inputs, I want the model to emit 9.740 as output.\"\n",
    "\n",
    "Model inputs are often represented by the variable x, and desired outputs by the variable y.  Similarly, the variable xs (the plural of x) represents a list of model inputs, and ys is a list of model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example model inputs and outputs:\n",
      "[0.0, 1.0] [-0.020806968]\n",
      "[3.0, 3.0] [-0.020843983]\n",
      "[4.0, 6.0] [0.01165545]\n",
      "[6.0, 8.0] [-0.010773897]\n",
      "[8.0, 11.0] [-0.021383047]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "\n",
    "training_data = \"example.csv\"  # You'll probably want to change this!\n",
    "\n",
    "xs = []  # will hold model inputs from all the training examples\n",
    "ys = []  # will hold model outputs from all the training examples\n",
    "\n",
    "\n",
    "for row in csv.reader(open(training_data, \"r\", encoding=\"utf-8-sig\")):\n",
    "    # Convert the entries in the row from strings to numbers\n",
    "    row = list(map(float, row))\n",
    "\n",
    "    x = row[:-1]  # model inputs, all but the last number in the row\n",
    "    y = row[-1:]  # desired model output, the last number in the row\n",
    "\n",
    "    xs.append(x)\n",
    "    ys.append(y)\n",
    "\n",
    "\n",
    "# Print the first five model inputs desired model outputs.\n",
    "print(\"Example model inputs and outputs:\")\n",
    "for i in range(5):\n",
    "    print(xs[i], ys[i])\n",
    "\n",
    "\n",
    "# Machine learning can involve a TON of computation.  To make this more\n",
    "# efficient, PyTorch needs training data in a special \"tensor\" format.\n",
    "# Here, we do the conversion into that format.\n",
    "\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Model\n",
    "\n",
    "We want to construct a model of that training data.  Given an input similar to one in the training data, the model should output a value close to the desired output.\n",
    "\n",
    "We do part of this job, and PyTorch does the rest.\n",
    "\n",
    "One of our responsibilities is to define the \"model architecture\", which is the rough form of the solution that PyTorch should seek.  But we can leave some parameters undetermined.  Later, PyToch will help us find good settings for those parameters.\n",
    "\n",
    "PyTorch provides lots of mathematical building blocks that you can use to define a model architecture.  In our concrete example, we will use the most common one, which is called a \"linear layer\".\n",
    "\n",
    "In our training examples, we specify two model inputs.  Let calls them x1 and x2.  A linear layer takes compute the function:\n",
    "\n",
    "    A * x1 + B * x2 + C\n",
    "\n",
    "where A, B, and C are parameters.  Later, we'll use PyTorch to figure out which values of these model parameters gives the best approximation of our training data.\n",
    "\n",
    "To model more complicated phenomena, you will will need to experiment with more powerful architectures.  The goal is to find an architecture complex enough to accurately model the phenomenon (presumably something related to FRC robotics), but otherwise as simple as possible so that the model is easy and inexpensive to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create building blocks of the model here.  If you want to\n",
    "        # model a more complicated phenomenon, you will need to a more\n",
    "        # complicated model architecture wit more building blocks.\n",
    "        self.linear1 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        # Now we take a training example input and compute the corresponding\n",
    "        # model output.  In an untrained model, this will likely be far\n",
    "        # from the desired output, specified in the training data.  But as\n",
    "        # the model trains, this output will get closer and closer to the\n",
    "        # desired output.\n",
    "        #\n",
    "        # Confusingly, we can work with either a single training example or\n",
    "        # a \"batch\" consisting of many training examples all at once.\n",
    "        return self.linear1(xs)\n",
    "\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Training a machine learning model involves several steps:\n",
    "\n",
    "  1. Shove one (or more) training example inputs into the model.\n",
    "  2. Compare the model's output to the desired output, expressing the difference as a quantity, called the \"loss\".\n",
    "  3. Use the loss to adjust the parameters inside the model.\n",
    "\n",
    "When the loss (difference between the model's actual output and desired\n",
    "output) get small enough, our model can come out of the oven!\n",
    "\n",
    "All of the steps above are done with mysterious PyTorch incantations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an \"optimizer\", which is used to adjust the model parameters so that model outputs more closely match desired outputs specified in the training data.  We'll use a popular algorithm called \"Adam\".\n",
    "\n",
    "There is an important number below called \"LR\", which you might want to fuss with, trying different values.\n",
    "\n",
    "LR stands for \"learning rate\".  This specifies how aggressively the optimizer should update model parameters.  To understand LR, imagine you are playing a game of \"getting warmer, getting colder\".  Suppose you take a step and hear, \"You're getting warmer!\"  Now, how many more steps should you take in the same direction?  You could be cautious and take just 1 step.  Or you could be bold and take 10.  Going 10 steps might get you to your destination faster, but you might overshoot the target.\n",
    "\n",
    "The optimizer faces the same challenge as it wanders around (varies model parameters) in search of the target (the best model, the one that most accurately reproduces the training data).  By setting the learning rate, you are advising the optimizer what strategy to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each training example, the model will produce some output.  This output will differ somewhat from the desired output specified in the training data.  We need some way to quantify this difference: how bad is the discrepancy?  PyTorch supports many choices, and you can define your own.\n",
    "\n",
    "In our concrete example, we will use a simple loss function called \"mean squared error\" or MSE for short.  Here is how it works.\n",
    "\n",
    "The loss is:\n",
    "\n",
    "    (model's actual output - desired output) ^ 2\n",
    "\n",
    "Here, \"^ 2\" means squared or multiplied by itself.  So, for example, if the model actually outputs 4, but the desired output is 6, then the MSE loss is (4 - 6) ^ 2 = (-2) ^ 2 = 4.  Usually, the loss is averaged over many training examples, which explains the word \"mean\" in the name.\n",
    "\n",
    "The MSE loss function says small errors are not bad, but big errors are super bad.  Arguably, this could give too much influence to a few faulty training examples produced by some sensor glitch. So this might be a choice worth reconsidering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual machine learning happens in this next bit!  This is called the training loop.  We'll repeatedly push training examples forward through the model, compute the loss (discrepancy between actual model output and desired model output), and then work backward through the model, updating the model parameters in hopes of reducing the loss next time.\n",
    "\n",
    "You might trying changing the number of times we go through the loop.  For example, you could try a higher learning rate and lower number of rounds or vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0 loss = 31.97720718383789\n",
      "round 1000 loss = 0.23800192773342133\n",
      "round 2000 loss = 0.08449573069810867\n",
      "round 3000 loss = 0.016991127282381058\n",
      "round 4000 loss = 0.004862884525209665\n",
      "round 5000 loss = 0.004318441264331341\n",
      "round 6000 loss = 0.004315678961575031\n",
      "round 7000 loss = 0.004315678961575031\n",
      "round 8000 loss = 0.004315678961575031\n",
      "round 9000 loss = 0.004315678961575031\n",
      "round 10000 loss = 0.004315678961575031\n",
      "round 11000 loss = 0.004315678961575031\n",
      "round 12000 loss = 0.004315678961575031\n",
      "round 13000 loss = 0.004315839149057865\n",
      "round 14000 loss = 0.004315678495913744\n",
      "round 15000 loss = 0.004316328093409538\n",
      "round 16000 loss = 0.0043157050386071205\n",
      "round 17000 loss = 0.004315678495913744\n",
      "round 18000 loss = 0.004315678961575031\n",
      "round 19000 loss = 0.004315714351832867\n"
     ]
    }
   ],
   "source": [
    "for round in range(20000):\n",
    "\n",
    "    # Prepare the optimizer for a pass through the training data.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute the actual model output for each training example.\n",
    "    # When people describe this process on paper, they often use the\n",
    "    # variable y with a little hat (^) on top.\n",
    "    yhats = model(xs)\n",
    "\n",
    "    # Use the loss function to quantify the discrepancy between the actual\n",
    "    # model outputs (yhats) and the desired outputs specified in the\n",
    "    # training data (ys).\n",
    "    loss = loss_function(yhats, ys)\n",
    "\n",
    "    # Work backward through the model, determining the best direction\n",
    "    # to modify each model parameter to reduce the lose, e.g. increase\n",
    "    # this variable a little, decrease that variable by twice as much, etc.\n",
    "    # This is called a \"gradient\".\n",
    "    loss.backward()\n",
    "\n",
    "    # Tell the optimizer to actually change the model parameters in hopes\n",
    "    # of reducing the loss.  The magnitude of these changes is affected\n",
    "    # by the learning rate and details of the optimization algorithm.\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print to loss every now and then so we can track progress in\n",
    "    # training the model.  Machine learning engineers spend a ridiculous\n",
    "    # amount of time and emotional energy watching loss numbers drop\n",
    "    # (and sometimes rise!) over time.  Welcome to the party!\n",
    "    if round % 1000 == 0:\n",
    "        print(\"round\", round, \"loss =\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output and Use the Model\n",
    "\n",
    "All the hard work is done!  Now we need to display the model on the screen or store the model to a file.  Here, we'll just print out the parameters. The interpretation of these parameters depends on the model architecture you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight Parameter containing:\n",
      "tensor([[ 0.0056, -0.0053]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-0.0047], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, parameters in model.named_parameters():\n",
    "    print(name, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the concrete example, the output is something like:\n",
    "\n",
    "    linear1.weight Parameter containing:\n",
    "    tensor([[6.9722, 2.9863]], requires_grad=True)\n",
    "    linear1.bias Parameter containing:\n",
    "      tensor([4.0468], requires_grad=True)\n",
    "\n",
    "This means that for input x1 and x2, the model outputs the value:\n",
    "\n",
    "    6.9722 * x1 + 2.9863 + 4.0468\n",
    "\n",
    "The example training data was generated using this formula:\n",
    "\n",
    "    output = 6 * x1 + 3 * x2 + 4 + random noise\n",
    "\n",
    "So the model has successfully rediscovered the principle used to produce the training data, despite the addition of random noise to make it harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple model with a simple expression that represents it. But if it were more complex, rather than infering the underlying expression in order to compute output values and plugging in values, we could instead just ask the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -0.004366518463939428\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create some sample input data\n",
    "sample_input = torch.tensor([1.0, 1.0])\n",
    "\n",
    "# Make predictions (_no_grad() turns off learning)\n",
    "with torch.no_grad():\n",
    "    predictions = model(sample_input)\n",
    "\n",
    "print(\"Prediction:\", predictions.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of our training (the parameter values) are stored in memory as part of the running program.  When this program ends, we lose that memory.  To save the parameters for future use, such as on the actual robot, we can save the parameters to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"controlbot.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, during a separate program execution, we can load the parameters back into the model and run predictions as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"controlbot.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's all!\n",
    "\n",
    "Hopefully, you can use machine learing to discover physical principles at play in FRC robotics, despite noisy sensors, motors, and occasionally crashing into stuff!\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
